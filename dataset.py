# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZwGGU8CseccgWl-NYIgJHGcQE3ha161x
"""

import torch
from torch.utils.data import Dataset, DataLoader

class MyDataset(Dataset):
  def __init__(self,max_seq_len,tokenizer,file_dir):
    premise=[]
    hypothesis=[]
    labels=[]
    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}
    with open(file_dir, 'r') as f:
      while True:
        src=f.readline()
        if src=='':
          break
        #print(src)
        src=src.split('\t')
        #print(src)
        premise.append(src[0])
        try:
          hypothesis.append(src[1])
        except:
          print(src)  
        labels.append(src[2].strip('\n'))
    labels=[label_set[label] for label in labels]

    self.len=len(labels)
    self.premise=tokenizer(premise)
    self.hypothesis=tokenizer(hypothesis)
    self.labels=labels
    self.max_seq_len=max_seq_len
    self.tokenizer=tokenizer
    print("premise",premise)
    print("tokenized_premise",self.premise)
    print("hypothesis",hypothesis)
    print("tokenized_hypothesis",self.hypothesis)
    print("labels",self.labels)


  def __getitem__(self,index):
      premise=self.premise[index]
      hypothesis=self.hypothesis[index]
      labels=self.labels[index]

      return {"premise" :torch.tensor(premise, dtype=torch.float64),
             "hypothesis" :torch.tensor(hypothesis, dtype=torch.float64),
             "labels":torch.tensor(labels,dtype=torch.float64)}


  def __len__(self):
    return self.len

  #def collate_fn(self,data):
    
